{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24353ed1-8aa8-44c8-82f5-c4e3ff04c886",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from datasets import load_dataset    \n",
    "from huggingface_hub import HfApi\n",
    "from datasets import DatasetDict\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import json\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2b9db0e-e3e3-4ede-83a3-f0529555b518",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config/set-dev.yaml') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    huggingface_token = config['Huggingface']['token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dbf3f72-883a-4c21-b20d-4ee7dfc6f09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"llama3.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46d583e7-7d65-407e-855b-adfc9114c915",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOllama(model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "501b984e-3e6e-466d-9022-678d4d89ef20",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Context information is below. You are only aware of this context and nothing else.\n",
    "---------------------\n",
    "\n",
    "{context}\n",
    "\n",
    "---------------------\n",
    "Given this context, generate only questions based on the below query.\n",
    "You are an Teacher/Professor in {domain}. \n",
    "Your task is to provide exactly **{num_questions}** question(s) for an upcoming quiz/examination. \n",
    "You are not to provide more or less than this number of questions. \n",
    "The question(s) should be diverse in nature across the document. \n",
    "The purpose of question(s) is to test the understanding of the students on the context information provided.\n",
    "You must also provide the answer to each question. The answer should be based on the context information provided only.\n",
    "\n",
    "Restrict the question(s) to the context information provided only.\n",
    "QUESTION and ANSWER should be written in Korean. response in JSON format which contains the `question` and `answer`.\n",
    "DO NOT USE List in JSON format.\n",
    "ANSWER should be a complete sentence.\n",
    "\n",
    "#Format:\n",
    "```json\n",
    "{{\n",
    "    \"QUESTION\": \"PMDU(prime minister’s delivery unit)가 어떤 역할을 하는 조직인가요?\",\n",
    "    \"ANSWER\": \"PMDU(Prime Minister’s Delivery Unit)는 일반적으로 국가 주요 우선 과제의 진행 상황을 감독하고 개선하기 위해 설립됩니다. \"\n",
    "}},\n",
    "{{\n",
    "    \"QUESTION\": \"조직 형태로서의 네트워크는 계층제와 시장이라는 조직형태에서 어떠한 특성을 가지는가?\",\n",
    "    \"ANSWER\": \"계층제적 지배구조는 수평적⋅수직적으로 분화되어 있고 지시⋅명령과 같은 행정적 수단에 의해 통제된다.\"    \n",
    "}},\n",
    "{{\n",
    "    \"QUESTION\": \"향후 발전을 위해 정부 역할은 어떻게 설정되어야 할까?\",\n",
    "    \"ANSWER\": \"정부역할에 대한 새로운 관심과 개혁 노력이 뒤따를 필요가 있다.\"    \n",
    "}}\n",
    "```\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78d83efb-3b5c-488b-8140-ec0520c5cd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_json_parser(response):\n",
    "    json_string = response.content.strip().removeprefix(\"```json\\n\").removesuffix(\"\\n```\").strip()\n",
    "    json_string = f'[{json_string}]'\n",
    "    json_fmt = json.loads(json_string)\n",
    "    print(type(json_fmt))\n",
    "    print(json_fmt)\n",
    "    return json_fmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eca9f76f-aecd-4292-bddb-63c8bd06519f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOllama(model=model_name, temperature=0, format='json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd337915-7e0b-4300-9c5c-cd3a72c611dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    prompt\n",
    "    | model\n",
    "    | custom_json_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c1a73c7-1ac0-4c30-b5c9-be01d14a909a",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_name = \"prismdata/KDI-DATASET-2014\"\n",
    "input_info = []\n",
    "input_info.append({\"FileName\":\"QA_input_docs/2014-05-정책효과성 증대를 위한 집행과학에 관한 연구.pdf.txt\", \n",
    "                  \"Source\":\"KDI 연구보고서 2014-05 정책효과성 증대를 위한 집행과학에 관한 연구 김재훈\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d363886b-77e8-4b69-861b-b15d23e0425a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_index = 0\n",
    "element_text = []\n",
    "with open(input_info[file_index][\"FileName\"], \"r\", encoding=\"utf-8\") as rf:\n",
    "    element_text = rf.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07ea8bef-cd38-4d6a-86b3-685098054d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_pair = []\n",
    "for idx, text_element in enumerate(tqdm(element_text)):\n",
    "    try:\n",
    "        if text_element.count('|') > 1:\n",
    "            print(\"Skeep Table Detect\")\n",
    "            continue\n",
    "        text_element = text_element.strip()\n",
    "        llm_rtn = chain.invoke({\"context\": f\"{text_element}\", \"domain\": \"report for policy study\", \"num_questions\": \"3\"})\n",
    "        qa_f = open(\"qa_debug.txt\", \"a\", encoding='utf-8')\n",
    "        if isinstance(llm_rtn, list):\n",
    "            for rtn_ele in llm_rtn:\n",
    "                output_string = f\"{idx} : {text_element}\\n\" \n",
    "                qa_f.write(output_string)\n",
    "                output_string = f\"{rtn_ele}\\n\" \n",
    "                qa_f.write(output_string)\n",
    "                qa_pair.extend(rtn_ele)\n",
    "        qa_f.close() \n",
    "        print(\"---\")\n",
    "    except Exception as e:\n",
    "        eqa_f = open(\"qa_error_debug.txt\", \"a\", encoding='utf-8')\n",
    "        eqa_f.write(text_element + '\\n' + str(e)+'\\n')\n",
    "        eqa_f.close()\n",
    "print(qa_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90076c22-39d4-4b1c-8537-c1eb1d473023",
   "metadata": {},
   "outputs": [],
   "source": [
    "#backup\n",
    "with open(\"qa_pair_llama3.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for qa in qa_pair:\n",
    "        if 'question' in qa.keys():\n",
    "            qa_grammar = {\n",
    "                \"question\": qa[\"question\"],\n",
    "                \"input\": \"\",\n",
    "                \"answer\": qa[\"answer\"],\n",
    "                \"source\": input_info[file_index][\"Source\"]\n",
    "            }\n",
    "        else:\n",
    "            qa_modified = {\n",
    "                \"question\": qa[\"QUESTION\"],\n",
    "                \"input\": \"\",\n",
    "                \"answer\": qa[\"ANSWER\"],\n",
    "                \"source\": input_info[file_index][\"Source\"]\n",
    "            }\n",
    "        f.write(json.dumps(qa, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f8fbc1f5-f645-4a7d-89b7-8025c5c31332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5348a69-6358-4d79-9011-05bf749da8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonl_file = \"qa_pair_llama3.jsonl\"\n",
    "dataset = load_dataset(\"json\", data_files=jsonl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e94d88-32ec-44d2-8515-a2e4bb216664",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_testvalid = dataset['train'].train_test_split(test_size=0.2)\n",
    "test_valid = train_testvalid['test'].train_test_split(test_size=0.5)\n",
    "ds = DatasetDict({\n",
    "    'train': train_testvalid['train'],\n",
    "    'test': test_valid['test'],\n",
    "    'valid': test_valid['train']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1ab04a-e6bc-4fc3-9fd3-c0d7b13f6444",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hugginfface push\n",
    "api = HfApi()\n",
    "ds.push_to_hub(repo_name, token=huggingface_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02490b7c-0a78-4adf-ae01-9a701b14c622",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
